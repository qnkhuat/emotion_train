{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 21 14:01:49 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    25W /  70W |    964MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1669      G   /usr/lib/xorg/Xorg                            80MiB |\n",
      "|    0      9330      C   .../qnkhuat/miniconda3/envs/dev/bin/python   873MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch \n",
    "from proxyless_nas import proxyless_cpu, proxyless_gpu, proxyless_mobile, proxyless_mobile_14,model_zoo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "from proxyless_nas.utils import AverageMeter, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/qnkhuat/data/emotion_compilation_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = proxyless_cpu(pretrained=True) # Yes, we provide pre-trained models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['download_url',\n",
       " 'partial',\n",
       " 'proxyless_base',\n",
       " 'proxyless_cpu',\n",
       " 'proxyless_gpu',\n",
       " 'proxyless_mobile',\n",
       " 'proxyless_mobile_14']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = sorted(name for name in model_zoo.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(model_zoo.__dict__[name]))\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://hanlab.mit.edu/files/proxylessNAS/proxyless_gpu.config\" to /home/qnkhuat/.torch/proxyless_nas/proxyless_gpu.config\n",
      "Downloading: \"http://hanlab.mit.edu/files/proxylessNAS/proxyless_gpu.pth\" to /home/qnkhuat/.torch/proxyless_nas/proxyless_gpu.pth\n"
     ]
    }
   ],
   "source": [
    "arch = 'proxyless_gpu'\n",
    "net = model_zoo.__dict__[arch](pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(os.path.join(data_path, \"train\"), transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(\n",
    "#             mean=[0.485, 0.456, 0.406],\n",
    "#             std=[0.229, 0.224, 0.225]\n",
    "#         ),\n",
    "    ])), batch_size=16, shuffle=True, num_workers=4, pin_memory=True, drop_last=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# linear scale the devices\n",
    "\n",
    "net = torch.nn.DataParallel(net).cuda()\n",
    "# net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/1521], Loss: 1.8484\n",
      "Epoch [1/3], Step [200/1521], Loss: 1.6710\n",
      "Epoch [1/3], Step [300/1521], Loss: 1.4955\n",
      "Epoch [1/3], Step [400/1521], Loss: 1.4561\n",
      "Epoch [1/3], Step [500/1521], Loss: 1.3288\n",
      "Epoch [1/3], Step [600/1521], Loss: 1.4612\n",
      "Epoch [1/3], Step [700/1521], Loss: 1.3329\n",
      "Epoch [1/3], Step [800/1521], Loss: 1.1890\n",
      "Epoch [1/3], Step [900/1521], Loss: 1.3507\n",
      "Epoch [1/3], Step [1000/1521], Loss: 1.7480\n",
      "Epoch [1/3], Step [1100/1521], Loss: 1.4517\n",
      "Epoch [1/3], Step [1200/1521], Loss: 0.8520\n",
      "Epoch [1/3], Step [1300/1521], Loss: 1.2050\n",
      "Epoch [1/3], Step [1400/1521], Loss: 1.1320\n",
      "Epoch [1/3], Step [1500/1521], Loss: 1.2786\n",
      "Epoch [2/3], Step [100/1521], Loss: 1.5303\n",
      "Epoch [2/3], Step [200/1521], Loss: 0.9381\n",
      "Epoch [2/3], Step [300/1521], Loss: 1.5120\n",
      "Epoch [2/3], Step [400/1521], Loss: 0.9579\n",
      "Epoch [2/3], Step [500/1521], Loss: 1.0768\n",
      "Epoch [2/3], Step [600/1521], Loss: 1.5546\n",
      "Epoch [2/3], Step [700/1521], Loss: 1.0084\n",
      "Epoch [2/3], Step [800/1521], Loss: 1.6433\n",
      "Epoch [2/3], Step [900/1521], Loss: 1.1445\n",
      "Epoch [2/3], Step [1000/1521], Loss: 0.4756\n",
      "Epoch [2/3], Step [1100/1521], Loss: 1.1627\n",
      "Epoch [2/3], Step [1200/1521], Loss: 0.8135\n",
      "Epoch [2/3], Step [1300/1521], Loss: 0.8795\n",
      "Epoch [2/3], Step [1400/1521], Loss: 1.0760\n",
      "Epoch [2/3], Step [1500/1521], Loss: 0.8222\n",
      "Epoch [3/3], Step [100/1521], Loss: 1.0278\n",
      "Epoch [3/3], Step [200/1521], Loss: 1.2121\n",
      "Epoch [3/3], Step [300/1521], Loss: 0.4274\n",
      "Epoch [3/3], Step [400/1521], Loss: 0.6679\n",
      "Epoch [3/3], Step [500/1521], Loss: 1.3473\n",
      "Epoch [3/3], Step [600/1521], Loss: 0.6877\n",
      "Epoch [3/3], Step [700/1521], Loss: 0.9962\n",
      "Epoch [3/3], Step [800/1521], Loss: 0.7638\n",
      "Epoch [3/3], Step [900/1521], Loss: 0.8048\n",
      "Epoch [3/3], Step [1000/1521], Loss: 0.9215\n",
      "Epoch [3/3], Step [1100/1521], Loss: 0.8047\n",
      "Epoch [3/3], Step [1200/1521], Loss: 0.3966\n",
      "Epoch [3/3], Step [1300/1521], Loss: 1.0988\n",
      "Epoch [3/3], Step [1400/1521], Loss: 0.5214\n",
      "Epoch [3/3], Step [1500/1521], Loss: 0.7874\n"
     ]
    }
   ],
   "source": [
    "total_step = len(data_loader)\n",
    "for epoch in range(3):\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 3, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(os.path.join(data_path, \"valid\"), transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])), batch_size=32, shuffle=True, num_workers=1, pin_memory=True, drop_last=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 69.28273681184419 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "net.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in valid_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(os.path.join(data_path, \"test\"), transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])), batch_size=32, shuffle=True, num_workers=1, pin_memory=True, drop_last=False,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 69.67519402127049 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "net.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
